{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOMy8lROqqXklSzTDASGnD9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YISEULKIM5217/AI-Project/blob/main/22000166_YiseulKim_DM_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making Spam Message Filter"
      ],
      "metadata": {
        "id": "5V_wAbqOEkUb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FswlyGP9Ee1q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/10.%20RNN%20Text%20Classification/dataset/spam.csv\", filename=\"spam.csv\")\n",
        "df = pd.read_csv('spam.csv', encoding = 'latin1', usecols=[0,1])"
      ],
      "metadata": {
        "id": "D3FcQLJ_GnS3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Label', 'Message']"
      ],
      "metadata": {
        "id": "1xte4hF4G75D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UObvjN5tHAhU",
        "outputId": "0c0a31ea-f74b-4c45-e739-dfdb797684ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Label                                            Message\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8PqZD7CyFoq",
        "outputId": "24653d3b-48f4-4382-842e-65f6994c4745"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Label                                            Message\n",
            "0      ham  Go until jurong point, crazy.. Available only ...\n",
            "1      ham                      Ok lar... Joking wif u oni...\n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      ham  U dun say so early hor... U c already then say...\n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
            "...    ...                                                ...\n",
            "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
            "5568   ham              Will Ì_ b going to esplanade fr home?\n",
            "5569   ham  Pity, * was in mood for that. So...any other s...\n",
            "5570   ham  The guy did some bitching but I acted like i'd...\n",
            "5571   ham                         Rofl. Its true to its name\n",
            "\n",
            "[5572 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Function to split messages into words"
      ],
      "metadata": {
        "id": "EnlovRmpHWMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to split messages into words\n",
        "def tokenize(message):\n",
        "  message = message.lower() # Convert to lowercase\n",
        "  words = re.findall(r'\\b\\w+\\b', message) # Extract words\n",
        "  return words"
      ],
      "metadata": {
        "id": "VgHFEXccHGLv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Separate spam and non-spam messages"
      ],
      "metadata": {
        "id": "TtTQUSBGHaWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate spam and non-spam messages\n",
        "spam_messages = df[df['Label'] == 'spam']['Message']\n",
        "non_spam_messages = df[df['Label'] =='ham']['Message']"
      ],
      "metadata": {
        "id": "5_fgY1p5HdFy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Count the number of spam messages"
      ],
      "metadata": {
        "id": "pzZdxfwuHzYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of spam messages\n",
        "spam_count = spam_messages.shape[0]\n",
        "\n",
        "#Print the result\n",
        "print(f\"Total number of spam messages : {spam_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6CkRQguH59c",
        "outputId": "3b563a8e-18e3-4e66-dd57-78fdb6064e7b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of spam messages : 747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Question 1 : How to get the number of non-spam(ham) messages?"
      ],
      "metadata": {
        "id": "xzwIGqJ9IGQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of non_spam messages\n",
        "non_spam_count = non_spam_messages.shape[0]\n",
        "\n",
        "#Print the result\n",
        "print(f\"Total number of non_spam messages : {non_spam_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfzIKhZLILLZ",
        "outputId": "df74dff9-451b-4f63-9250-6313a4beee16"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of non_spam messages : 4825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Calculate word frequency"
      ],
      "metadata": {
        "id": "GH-oIAd2IV1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Calculate word frequency\n",
        "spam_words = Counter()\n",
        "non_spam_words = Counter()\n",
        "\n",
        "for message in spam_messages :\n",
        "  spam_words.update(tokenize(message))\n",
        "\n",
        "for message in non_spam_messages :\n",
        "  non_spam_words.update(tokenize(message))"
      ],
      "metadata": {
        "id": "0gvK39zTIY-T"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Print the most common words"
      ],
      "metadata": {
        "id": "lAvsHwfhI3Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the most common words\n",
        "print(\"Most common words in spam messages :\")\n",
        "print(spam_words.most_common(30))\n",
        "\n",
        "print(\"\\nMost common words in non-spam messages:\")\n",
        "print(non_spam_words.most_common(30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIdCZYiEI5jT",
        "outputId": "afdea3ca-3b1d-4091-9376-71377d1a9674"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common words in spam messages :\n",
            "[('to', 688), ('a', 377), ('call', 355), ('å', 299), ('you', 297), ('your', 264), ('free', 224), ('2', 206), ('the', 206), ('for', 203), ('now', 199), ('or', 188), ('u', 174), ('txt', 163), ('is', 158), ('on', 144), ('ur', 144), ('4', 137), ('have', 135), ('from', 131), ('mobile', 127), ('text', 125), ('and', 122), ('stop', 121), ('claim', 113), ('1', 111), ('with', 109), ('reply', 104), ('www', 98), ('of', 95)]\n",
            "\n",
            "Most common words in non-spam messages:\n",
            "[('i', 2940), ('you', 1943), ('to', 1554), ('the', 1122), ('a', 1056), ('u', 1018), ('and', 857), ('in', 818), ('me', 772), ('my', 750), ('is', 732), ('it', 711), ('that', 551), ('of', 525), ('for', 501), ('s', 478), ('have', 440), ('can', 439), ('so', 435), ('but', 434), ('your', 417), ('not', 415), ('are', 414), ('m', 405), ('on', 393), ('do', 384), ('at', 378), ('t', 375), ('if', 354), ('we', 354)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Question 2: Do you think is it meaningful to use the most common words in each message category to make a spam filter? Explain why."
      ],
      "metadata": {
        "id": "E1F4sQMZJHYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I don't think so. As you can see in the result, the most common words in each message of spam and non-spam words overlap.\n",
        "# So, instead of using most common words, it seems to be better to find words that are used more in spam then non-spam messages.\n",
        "# Better is to make use of both type of words. Words that appear more frequently in spam messages, and\n",
        "# words that appear more frequently in non-spam messages."
      ],
      "metadata": {
        "id": "kRaeaURYJPJN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Identify words that are more frequent in spam than in non-spam"
      ],
      "metadata": {
        "id": "gvMBFrsBJkcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify words that are more frequent in spam than in non-spam\n",
        "# Compare the frequency of each word in spam and non-spam\n",
        "unique_words = set(list(spam_words.keys())+\n",
        "                   list(non_spam_words.keys()))\n",
        "spam_dominant_words = {}\n",
        "\n",
        "for word in unique_words:\n",
        "  spam_freq = spam_words[word]\n",
        "  non_spam_freq = non_spam_words[word]\n",
        "  # Select the word if it is significantly more frequent in spam\n",
        "  if spam_freq > non_spam_freq * 2: #This ratio can be adjusted\n",
        "    spam_dominant_words[word] = spam_freq\n",
        "\n",
        "# Print the results\n",
        "print(\"Words more frequent in spam than in non-spam:\")\n",
        "#for word, freq in sorted(spam_dominant_words.items(), key=lambda x: x[1], reverse=True) :\n",
        "#  print(f\"{word}: {freq}\")\n",
        "\n",
        "len(spam_dominant_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZzoiT_-JqcX",
        "outputId": "cbecd9bd-a0d1-4b6d-f560-2de5b99b91b0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words more frequent in spam than in non-spam:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1988"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Question 3 : If you want to identify words that are a way more frequent in spam than in non-spam, how are you going to modify the previous code?"
      ],
      "metadata": {
        "id": "-V_E136EKuax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify words that are \"way\" more frequent in spam than in non-spam\n",
        "# Compare the frequency of each word in spam and non-spam\n",
        "unique_words = set(list(spam_words.keys())+\n",
        "                   list(non_spam_words.keys()))\n",
        "modified_spam_dominant_words = {}\n",
        "\n",
        "for word in unique_words:\n",
        "  spam_freq = spam_words[word]\n",
        "  non_spam_freq = non_spam_words[word]\n",
        "  # For finding words that appear more frequently in spam messages,\n",
        "  # You must take control of the words that do not appear once in the non-spam messages.\n",
        "  # These words may appear frequently in spam messages, but may appear only one or twice in spam messages.\n",
        "  # If so, then the program cannot distinguish the difference since 0 has been take into account.\n",
        "  # To avoid this we +1 the 0 appeared word.\n",
        "  if non_spam_freq == 0 :\n",
        "      non_spam_freq = 1\n",
        "  # Select the word if it is significantly more frequent in spam\n",
        "  if spam_freq > non_spam_freq * 20: # Ratio adjusted to show words that are way more frequent in spam\n",
        "    modified_spam_dominant_words[word] = spam_freq\n",
        "\n",
        "# Print the results\n",
        "print(\"Words more frequent in spam than in non-spam:\")\n",
        "for word, freq in sorted(modified_spam_dominant_words.items(), key=lambda x: x[1], reverse=True) :\n",
        "  print(f\"{word}: {freq}\")\n"
      ],
      "metadata": {
        "id": "M8w6dj5kXhTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Question 4 : How many words do you want to pick to make your spam filter? What are the words?"
      ],
      "metadata": {
        "id": "szxJ5UPjMK6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I want to pick top 30 words to make my spam filter.\n",
        "\n",
        "# Code added to show only the top 50 frequent word in spam message\n",
        "count = 0\n",
        "spam_filter_words = {}\n",
        "print(\"Words more frequent in spam than in non-spam:\")\n",
        "for word, freq in sorted(modified_spam_dominant_words.items(), key=lambda x: x[1], reverse=True) :\n",
        "  if count > 15 :\n",
        "    break\n",
        "  else :\n",
        "    print(f\"{word}\")\n",
        "    spam_filter_words[count] = word\n",
        "    count = count + 1\n",
        "\n",
        "# The words are the result shown below."
      ],
      "metadata": {
        "id": "5A5cN-MGMQNx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef06287-ff72-41f3-fa5d-e095c27ba452"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words more frequent in spam than in non-spam:\n",
            "å\n",
            "claim\n",
            "www\n",
            "prize\n",
            "uk\n",
            "150p\n",
            "nokia\n",
            "tone\n",
            "co\n",
            "18\n",
            "16\n",
            "guaranteed\n",
            "cs\n",
            "500\n",
            "1000\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Refer to the following codes if you think you need."
      ],
      "metadata": {
        "id": "lMPubOmCMQpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check if a word is in a message\n",
        "def is_word_in_message(word, message):\n",
        "  message = message.lower()\n",
        "  words = set(re.findall(r'\\b\\w+\\b', message)) #Extract words and convert to a set\n",
        "  return word in words"
      ],
      "metadata": {
        "id": "ze0O3LSPMrDF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the word to search for\n",
        "search_word = 'å'.lower() # Replace with your specific word\n",
        "\n",
        "# Filter spam messages\n",
        "spam_messages = df[df['Label'] == 'spam']['Message']\n",
        "\n",
        "# Count how many spam messages contain the word\n",
        "count = sum(is_word_in_message(search_word, message) for message in spam_messages)\n",
        "\n",
        "# Print the result\n",
        "print(f\"The word '{search_word}' appears {count} in spam_messages.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjna9iJ0M9kM",
        "outputId": "57e6aea1-eefb-4043-dc6c-9470e7513729"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word 'å' appears 239 in spam_messages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the word to search for\n",
        "search_word = 'å'.lower() # Replace with your specific word\n",
        "\n",
        "# Filter spam messages\n",
        "non_spam_messages = df[df['Label'] == 'ham']['Message']\n",
        "\n",
        "# Count how many spam messages contain the word\n",
        "count = sum(is_word_in_message(search_word, message) for message in non_spam_messages)\n",
        "\n",
        "# Print the result\n",
        "print(f\"The word '{search_word}' appears {count} in non_spam_messages.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79iCQVMskpDL",
        "outputId": "9babeb7d-4d4b-48c6-8031-63eb132c2c3c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word 'å' appears 4 in non_spam_messages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Question 5 : Using the multi-words filtering method covered in the class, implement a function that determines if a given input message is a spam or not. (Suppose the decision threshold is set to 90%.)"
      ],
      "metadata": {
        "id": "0MkC7fJzN9S-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('Label', axis=1) # features\n",
        "y = df['Label'] # label\n",
        "\n",
        "# Split the dataset into 75% training and 25% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "W98kFVL4Ymef"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# about 7% are spam in both train and test data set\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming y_train is a pandas Series\n",
        "y_train_series = pd.Series(y_train)\n",
        "\n",
        "# Count the occurrences of each class\n",
        "class_counts = y_train_series.value_counts()\n",
        "\n",
        "# Display the counts\n",
        "print(class_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sBKaOjuZKMs",
        "outputId": "c58400bf-02fb-46f0-d5c0-ca6075ef261e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ham     3623\n",
            "spam     556\n",
            "Name: Label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJQXqBS4lEvu",
        "outputId": "a3572571-a540-411e-f94d-2bded7c77ff5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math, random, re, glob\n",
        "import pandas as pd\n",
        "from konlpy.tag import Okt"
      ],
      "metadata": {
        "id": "JFN7zwZakX06"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_words(training_set):\n",
        "  counts = defaultdict(lambda: [0,0])\n",
        "  training_set_arr = training_set.values\n",
        "  for is_spam, message in traning_set_arr:\n",
        "    for word in tokenize(message):\n",
        "      counts[word][int(is_spam)] += 1\n",
        "  return counts"
      ],
      "metadata": {
        "id": "99ZyYhpkj5Qb"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_probabilities(counts, total_non_spams, total_spams, k=0.9):\n",
        "  return [(w,\n",
        "           (non_spam + k) / (total_non_spams + 2 * k),\n",
        "           (spam + k) / (total_non_spams + 2 * k))\n",
        "  for w, (non_spam, spam) in counts.items()]"
      ],
      "metadata": {
        "id": "pj5h4t4sgJwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spam_probability(word_probs, message):\n",
        "  message_words = tokenize(message)\n",
        "  log_prob_if_spam = log_prob_if_not_spam = 0.0\n",
        "\n",
        "  for word, prob_if_not_spam, prob_if_spam in word_probs:\n",
        "    if word in message_words :\n",
        "      log_prob_if_spam += math.log(prob_if_spam)\n",
        "    else:\n",
        "      log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
        "\n",
        "  prob_if_spam = math.exp(log_prob_if_spam)\n",
        "\n",
        "  max_Proba = 0\n",
        "  index_Proba = ''\n",
        "  if max_Proba < (prob_if_spam / (prob_if_spam + prob_if_not_spam)) :\n",
        "    max_Proba = prob_if_spam / (prob_if_spam + prob_if_not_spam)\n",
        "    index_Proba = 'spam'\n",
        "\n",
        "  return max_Proba, index_Proba\n"
      ],
      "metadata": {
        "id": "2RIixw8WeeQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier:\n",
        "  def __init__(self, k=0.9):\n",
        "    self.k = k\n",
        "    self.word_probs = []\n",
        "\n",
        "  def classify(self, message):\n",
        "    return spam_probability(self.word_probs, message)\n",
        "\n",
        "  def train(self, training_set):\n",
        "    num_non_spams = len(traning_set[training_set.is_spam == '0'])\n",
        "    num_spams = len(traning_set[training_set.is_spam == '1'])\n",
        "\n",
        "    word_counts = count_words(training_set)\n",
        "    self.word_probs = word_probabilities(word_counts, num_non_spams, num_spams, self.k)"
      ],
      "metadata": {
        "id": "JZwFdQvweGs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def p_spam_give_word(word_prob):\n",
        "  word, prob_if_spam, prob_if_not_spam = word_prob\n",
        "  return prob_if_spam / (prob_if_spam + porb_if_not_spam)"
      ],
      "metadata": {
        "id": "8lwIzoTjgq7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_test_model(data, sw, predicsMess=''):\n",
        "  if sw == '0':\n",
        "    randoms.seed(0)\n",
        "    train_data, test_data = train_test_split(data, test_size=0.25)\n",
        "    print(\"train_data_cnt:\", len(train_data))\n",
        "    print(\"test_data_Cnt:\", len(test_data))\n",
        "\n",
        "    classifier = NaiveBayesClassifier()\n",
        "    classifier.train(train_data)\n",
        "\n",
        "    test_data_arr = test_data.values\n",
        "    classified = [(is_spam, message, classifier.classify(message)) for is_spam, message in test_data_arr]\n",
        "    print(classified)\n",
        "  else:\n",
        "    random.seed(0)\n",
        "    train_data, test_data = train_test_split(data, test_size = 0)\n",
        "    classifier = NaiveBayesClassifier()\n",
        "    classifier.train(train_data)\n",
        "    spam_probability = classifier.classify(predicMess)\n",
        "    print(spam_probability)\n",
        "    print(spam_probability[0])\n",
        "\n",
        "    if spam_probability[0] > 0.9:\n",
        "      print(\"Its Spam Message.\")\n",
        "    else :\n",
        "      print(\"Its Non-spam Message.\")\n"
      ],
      "metadata": {
        "id": "Ahqtvjnbg3OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def isSpam(predicMessage, mode):\n",
        "  train_and_test_model(trainData, mode, predicMessage)"
      ],
      "metadata": {
        "id": "mlOE7oWNit5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Question 6 : Change the number of words you used and test the performance."
      ],
      "metadata": {
        "id": "70GGlgoQOJFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check if a message is spam\n",
        "def is_spam(message):\n",
        "    # List of spam-indicative words (add more as needed)\n",
        "    spam_words = ['claim', 'prize', '150p', 'tone', '18']\n",
        "\n",
        "    # Count how many spam-indicative words are present in the message\n",
        "    spam_word_count = sum(is_word_in_message(word, message) for word in spam_words)\n",
        "\n",
        "    # Calculate the percentage of spam-indicative words\n",
        "    percentage_spam = (spam_word_count / len(message.split(' '))) * 100\n",
        "\n",
        "    # Check if the percentage exceeds the decision threshold (90%)\n",
        "    return percentage_spam >= 90"
      ],
      "metadata": {
        "id": "bgEjdEX1OOAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function with example messages\n",
        "messages_to_check = ['claim the prize', 'hello, this is not spam', '500 prize guaranteed']\n",
        "\n",
        "for message in messages_to_check:\n",
        "    if is_spam(message):\n",
        "        print(f\"The message '{message}' is likely spam.\")\n",
        "    else:\n",
        "        print(f\"The message '{message}' is not spam.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKvoPy04RxGE",
        "outputId": "6a7d3f8b-dd44-406c-cbe7-cff569edc0e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The message 'claim the prize' is not spam.\n",
            "The message 'hello, this is not spam' is not spam.\n",
            "The message '500 prize guaranteed' is not spam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Question 7 : Analyze (discuss) the advantages and disadvantages of the spam filter method implemented through this assignment."
      ],
      "metadata": {
        "id": "DTIAv7ZhOOb4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jda1hAEuOWn0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}